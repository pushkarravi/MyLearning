{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Code Snippets for Data Exploration in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippets for Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files, Selecting Columns, and Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in a file from local computer or directly from a URL\n",
    "# various file formats that can be read in out wrote out\n",
    "\n",
    "‘’’\n",
    "Format Type     Data Description      Reader           Writer\n",
    "text                  CSV            read_csv          to_csv\n",
    "text                 JSON            read_json         to_json\n",
    "text                 HTML            read_html         to_html\n",
    "text             Local clipboard  read_clipboard     to_clipboard\n",
    "binary             MS Excel          read_excel        to_excel\n",
    "binary            HDF5 Format        read_hdf           to_hdf\n",
    "binary           Feather Format     read_feather      to_feather\n",
    "binary              Msgpack         read_msgpack      to_msgpack\n",
    "binary               Stata           read_stata        to_stata\n",
    "binary                SAS             read_sas \n",
    "binary        Python Pickle Format   read_pickle       to_pickle\n",
    "SQL                   SQL             read_sql          to_sql\n",
    "SQL             Google Big Query      read_gbq          to_gbq\n",
    "‘’’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To read about different types of files, and further functionality of reading in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(‘local_path/file.csv’)\n",
    "df = pd.read_csv(‘https://file_path/file.csv')\n",
    "\n",
    "# when reading in tables, can specify separators, \n",
    "#and note a column to be used as index separators can include tabs (“\\t”), commas(“,”), pipes (“|”), etc.\n",
    "df = pd.read_table(‘https://file_path/file', sep=’|’, index_col=’column_x’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the df data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df           # print the first 30 and last 30 rows\n",
    "type(df)     # DataFrame\n",
    "df.head()    # print the first 5 rows\n",
    "df.head(10)  # print the first 10 rows\n",
    "df.tail()    # print the last 5 rows\n",
    "df.index     # “the index” (aka “the labels”)\n",
    "df.columns   # column names (which is “an index”)\n",
    "df.dtypes    # data types of each column\n",
    "df.shape     # number of rows and columns\n",
    "df.values    # underlying numpy array — df are stored as numpy arrays for effeciencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting a Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘column_y’]         # select one column\n",
    "type(df[‘column_y’])   # determine datatype of column (e.g., Series)\n",
    "df.column_y            # select one column using the DataFrame attribute — not effective if column names have spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize (describe) the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()                   # describe all numeric columns\n",
    "df.describe(include=[‘object’]) # describe all object columns\n",
    "df.describe(include=’all’)      # describe all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize (describe) a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_y.describe()   # describe a single column\n",
    "df.column_z.mean()       # only calculate the mean\n",
    "df[“column_z”].mean()    # alternate method for calculating mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the number of occurrences of each value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_y.value_counts()   # most useful for categorical variables, but can also be used with numeric variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter df by one column, and print out values of another column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when using numeric values, no quotations\n",
    "df[df.column_y == “string_value”].column_z\n",
    "df[df.column_y == 20 ].column_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display only the number of rows of the ‘df’ DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the 3 most frequent occurances of column in ‘df’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_y.value_counts()[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean filtering: only show df with column_z < 20\n",
    "filter_bool = df.column_z < 20    # create a Series of booleans…\n",
    "df[filter_bool]                # …and use that Series to filter rows\n",
    "df[filter_bool].describe()     # describes a data frame filtered by filter_bool\n",
    "df[df.column_z < 20]           # or, combine into a single step\n",
    "df[df.column_z < 20].column_x  # select one column from the filtered results\n",
    "df[df[“column_z”] < 20].column_x     # alternate method \n",
    "df[df.column_z < 20].column_x.value_counts()   # value_counts of resulting Series, can also use .mean(), etc. instead of .value_counts()\n",
    "\n",
    "\n",
    "# boolean filtering with multiple conditions; indexes are in square brackets, conditions are in parens\n",
    "df[(df.column_z < 20) & (df.column_y==’string’)] # ampersand for AND condition \n",
    "df[(df.column_z < 20) | (df.column_z > 60)] # pipe for OR condition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_z.order()          # sort a column\n",
    "df.sort_values(‘column_z’)   # sort a DataFrame by a single column\n",
    "df.sort_values(‘column_z’, ascending=False)     # use descending order instead\n",
    "# Sort dataframe by multiple columns\n",
    "df = df.sort([‘col1’,’col2',’col3'],ascending=[1,1,0]) \n",
    " \n",
    "# can also filter ‘df’ using pandas.Series.isin \n",
    "df[df.column_x.isin([“string_1”, “string_2”])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming, Adding, and Removing Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename one or more columns\n",
    "df.rename(columns={‘original_column_1’:’column_x’, ‘original_column_2’:’column_y’}, inplace=True) #saves changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace all column names (in place)\n",
    "new_cols = [‘column_x’, ‘column_y’, ‘column_z’]\n",
    "df.columns = new_cols\n",
    "\n",
    "# replace all column names when reading the file\n",
    "df = pd.read_csv(‘df.csv’, header=0, names=new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a new column as a function of existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘new_column_1’] = df.column_x + df.column_y\n",
    "df[‘new_column_2’] = df.column_x * 1000   #can create new columns without for loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(‘column_x’, axis=1)   # axis=0 for rows, 1 for columns — does not drop in place\n",
    "df.drop([‘column_x’, ‘column_y’], axis=1, inplace=True) # drop multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower-case all DataFrame column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = map(str.lower, df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Even more fancy DataFrame column re-naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower-case all DataFrame column names (for example)\n",
    "df.rename(columns=lambda x: x.split(‘.’)[-1], inplace=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values are usually excluded by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_x.value_counts()             # excludes missing values\n",
    "df.column_x.value_counts(dropna=False) # includes missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing values in a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_x.isnull()  # True if missing\n",
    "df.column_x.notnull() # True if not missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a boolean Series to filter DataFrame rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.column_x.isnull()]  # only show rows where column_x is missing\n",
    "df[df.column_x.notnull()] # only show rows where column_x is not missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()       # sums “down” the 0 axis (rows)\n",
    "df.sum(axis=0) # equivalent (since axis=0 is the default)\n",
    "df.sum(axis=1) # sums “across” the 1 axis (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding booleans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([True, False, True])       # create a boolean Series\n",
    "pd.Series([True, False, True]).sum() # converts False to 0 and True to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find missing values in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull() # DataFrame of booleans\n",
    "df.isnull().sum() # count the missing values in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop a row if ANY values are missing, defaults to rows, but can be applied to columns with axis=1\n",
    "df.dropna(inplace=True)  \n",
    "\n",
    "df.dropna(how=’all’, inplace=True)  # drop a row only if ALL values are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_x.fillna(value=’NA’, inplace=True) \n",
    "# fill in missing values with ‘NA’\n",
    "# value does not have to equal a string — can be set as some calculated value \n",
    "#like df.column_x.mode(), or just a number like 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn off the missing value filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(‘df.csv’, header=0, names=new_cols, na_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split-Apply-Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Split-Apply-Combine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each value in column_x, calculate the mean column_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(‘column_x’).column_y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each value in column_x, count the number of occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_x.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each value in column_x, describe column_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(‘column_x’).column_y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar, but outputs a DataFrame and can be customized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’])\n",
    "df.groupby(‘column_x’).column_y.agg([‘count’, ‘mean’, ‘min’, ‘max’]).sort_values(‘mean’)\n",
    "#if you don’t specify a column to which the aggregation function should be applied, \n",
    "#it will be applied to all numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(‘column_x’).mean()\n",
    "df.groupby(‘column_x’).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can also groupby a list of columns, i.e., for each combination of column_x and column_y, calculate the mean column_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([“column_x”,”column_y”]).column_z.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To take groupby results out of hierarchical index format (e.g., present as table), use .unstack() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(“column_x”).column_y.value_counts().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversely, if you want to transform a table into a hierarchical index, use the .stack() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Multiple Columns and Filtering Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = [‘column_x’, ‘column_y’]  # create a list of column names…\n",
    "df[my_cols]                         # …and use that list to select columns\n",
    "df[[‘column_x’, ‘column_y’]]        # or, combine into a single step — double brackets due to indexing a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use loc to select columns by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, ‘column_x’]                # colon means “all rows”, then select one column\n",
    "df.loc[:, [‘column_x’, ‘column_y’]]  # select two columns\n",
    "df.loc[:, ‘column_x’:’column_y’]     # select a range of columns (i.e., selects all columns including first through last specified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc can also filter rows by “name” (the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, :]                       # row 0, all columns\n",
    "df.loc[0:2, :]                     # rows 0/1/2, all columns\n",
    "df.loc[0:2, ‘column_x’:’column_y’] # rows 0/1/2, range of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use iloc to filter rows and select columns by integer position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:, [0, 3]]     # all rows, columns in position 0/3\n",
    "df.iloc[:, 0:4]        # all rows, columns in position 0/1/2/3\n",
    "df.iloc[0:3, :]        # rows in position 0/1/2, all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out and dropping rows based on condition (e.g., where column_x values are null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_rows = df[df[“column_x”].isnull()]\n",
    "new_df = df[~df.isin(drop_rows)].dropna(how=’all’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and Concatenating Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating two dfs together \n",
    "(just smooshes them together, does not pair them in any meaningful way) \n",
    " - axis=1 concats df2 to right side of df1 \n",
    " - axis=0 concats df2 to bottom of df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dfs based on paired columns\n",
    " - columns do not need to have same name\n",
    " - should match values\n",
    " - left_on column comes from df1, right_on column comes from df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df1, df2, left_on=’column_x’, right_on=’column_y’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can also merge slices of dfs together, though slices need to include columns used for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df1[['column_x1', 'column_x2']], df2, left_on='column_x2', right_on='column_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging two dataframes based on shared index values (left is df1, right is df2)\n",
    "new_df = pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Frequently Used Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map existing values to a different set of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘column_x’] = df.column_y.map({‘F’:0, ‘M’:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode strings as integer values (automatically starts at 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘column_x_num’] = df.column_x.factorize()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_x.nunique()   # count the number of unique values\n",
    "df.column_x.unique()    # return the unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace all instances of a value in a column (must match entire value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_y.replace(‘old_string’, ‘new_string’, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter values in one column based on values in another column (changes occur in place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use either .loc or .ix methods\n",
    "\n",
    "df.loc[df[“column_x”] == 5, “column_y”] = 1\n",
    "df.ix[df.column_x == “string_value”, “column_y”] = “new_string_value”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose data frame (i.e. rows become columns, columns become rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String methods are accessed via ‘str’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_y.str.upper() # converts to uppercase\n",
    "df.column_y.str.contains(‘value’, na=’False’) # checks for a substring, returns boolean series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert a string to the datetime_column format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘time_column’] = pd.to_datetime_column(df.time_column)\n",
    "df.time_column.dt.hour                                # datetime_column format exposes convenient attributes\n",
    "(df.time_column.max() — df.time_column.min()).days    # also allows you to do datetime_column “math”\n",
    "df[df.time_column > pd.datetime_column(2014, 1, 1)]   # boolean filtering with datetime_column format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting and then removing an index, resetting index can help remove hierarchical indexes while preserving the table in its basic structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(‘time_column’, inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort a column by its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.column_y.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the data type of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘column_x’] = df.column_x.astype(‘float’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the data type of a column when reading in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(‘df.csv’, dtype={‘column_x’:float})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variables for ‘column_x’ and exclude first dummy column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_x_dummies = pd.get_dummies(df.column_x).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate two DataFrames (axis=0 for rows, axis=1 for columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, column_x_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less Frequently Used Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({‘column_x’:[‘value_x1’, ‘value_x2’, ‘value_x3’], ‘column_y’:[‘value_y1’, ‘value_y2’, ‘value_y3’]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame from a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([[‘value_x1’, ‘value_y1’], [‘value_x2’, ‘value_y2’], [‘value_x3’, ‘value_y3’]], columns=[‘column_x’, ‘column_y’])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated()                                            # True if a row is identical to a previous row\n",
    "df.duplicated().sum()                                      # count of duplicates\n",
    "df[df.duplicated()]                                        # only show duplicates\n",
    "df.drop_duplicates()                                       # drop duplicate rows\n",
    "df.column_z.duplicated()                                   # check a single column for duplicates\n",
    "df.duplicated([‘column_x’, ‘column_y’, ‘column_z’]).sum()  # specify columns for finding duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up missing values in multiple DataFrame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({\n",
    " ‘col1’: ‘missing’,\n",
    " ‘col2’: ‘99.999’,\n",
    " ‘col3’: ‘999’,\n",
    " ‘col4’: ‘missing’,\n",
    " ‘col5’: ‘missing’,\n",
    " ‘col6’: ‘99’\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate two DataFrame columns into a new, single column - (useful when dealing with composite keys, for example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘newcol’] = df[‘col1’].map(str) + df[‘col2’].map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing calculations with DataFrame columns that have missing values\n",
    "#### In example below, swap in 0 for df[‘col1’] cells that contain null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘new_col’] = np.where(pd.isnull(df[‘col1’]),0,df[‘col1’]) + df[‘col2’]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a cross-tabulation of two Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.column_x, df.column_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative syntax for boolean filtering (noted as “experimental” in the documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(‘column_z < 20’)                         # df[df.column_z < 20]\n",
    "df.query(“column_z < 20 and column_y==’string’”)  # df[(df.column_z < 20) & (df.column_y==’string’)]\n",
    "df.query(‘column_z < 20 or column_z > 60’)        # df[(df.column_z < 20) | (df.column_z > 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop through rows in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print (index, row[‘column_x’])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much faster way to loop through DataFrame rows if you can work with tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.itertuples():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of non-numeric values throughout a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns.values:\n",
    "    df[col] = df[col].replace(‘[⁰-9]+.-’, ‘’, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change all NaNs to None (useful before loading to a db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where((pd.notnull(df)), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split delimited values in a DataFrame column into two new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘new_col1’], df[‘new_col2’] = zip(*df[‘original_col’].apply(lambda x: x.split(‘: ‘, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse hierarchical column indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the memory usage of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()         # total usage\n",
    "df.memory_usage() # usage by column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change a Series to the ‘category’ data type (reduces memory usage and increases performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘column_y’] = df.column_y.astype(‘category’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporarily define a new column as a function of existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.assign(new_column = df.column_x + df.spirit + df.column_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit which rows are read when reading in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(‘df.csv’, nrows=10)        # only read first 10 rows\n",
    "pd.read_csv(‘df.csv’, skiprows=[1, 2]) # skip the first two rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly sample a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac=0.75, random_column_y=1) # will contain 75% of the rows\n",
    "test = df[~df.index.isin(train.index)] # will contain the other 25%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the maximum number of rows and columns printed (‘None’ means unlimited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(‘max_rows’, None) # default is 60 rows\n",
    "pd.set_option(‘max_columns’, None) # default is 20 columns\n",
    "print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset options to defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option(‘max_rows’)\n",
    "pd.reset_option(‘max_columns’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the options temporarily (settings are restored when you exit the ‘with’ block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(‘max_rows’, None, ‘max_columns’, None):\n",
    "    print df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ~~ Created by Pushkar Ravi on 17th September 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference URL: https://medium.com/@msalmon00/helpful-python-code-snippets-for-data-exploration-in-pandas-b7c5aed5ecb9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
