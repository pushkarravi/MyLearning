{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><span style='background :yellow'>Data Science - Statistics & Mathematics</span></center>\n",
    "\n",
    "---\n",
    "\n",
    "**Ref URL**\n",
    "- [Analytics Vidhya - Ultimate Data Science - Statistics Mathematics Cheat Sheet](https://medium.com/analytics-vidhya/your-ultimate-data-science-statistics-mathematics-cheat-sheet-d688a48ad3db)\n",
    "- [Analytics Vidhya - Confusion Matrix-Accuracy-Precision-Recall-F1 Score](https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd)\n",
    "- [Towards Data Science - Accuracy, Precision, Recall or F1](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)\n",
    "- [Towards Data Science - Decoding Confusion Matrix](https://towardsdatascience.com/decoding-the-confusion-matrix-bb4801decbb)\n",
    "- [Medium - Classification Report](https://medium.com/@kennymiyasato/classification-report-precision-recall-f1-score-accuracy-16a245a437a5)\n",
    "- [Building Intelligence Together - Model Selection: Accuracy, Precision, Recall or F1](https://koopingshung.com/blog/machine-learning-model-selection-accuracy-precision-recall-f1/)\n",
    "- [Data School - Guide to Confusion Matrix](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)\n",
    "- [Blogspot - Confusion Matrix](https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = green>Topics</font>\n",
    "\n",
    "### Classifier Metrics\n",
    "1. Confusion Matrix\n",
    "2. Sensitivity / Recall\n",
    "3. Specificity\n",
    "4. Precision\n",
    "5. F1 score\n",
    "\n",
    "---\n",
    "\n",
    "### Regressor Metrics\n",
    "1. Mean Absolute Error (MAE)\n",
    "2. Mean Square Error (MSE)\n",
    "3. Root Mean Square Error (RMSE)\n",
    "4. Mean Squared Logarithmic Error (MSLE)\n",
    "5. R² (R is correlation coefficient)\n",
    "\n",
    "---\n",
    "\n",
    "### Statistical Indicators\n",
    "1. Correlation Coefficient\n",
    "2. Covariance\n",
    "3. Variance\n",
    "4. Standard Deviation\n",
    "\n",
    "---\n",
    "\n",
    "### Types of Distributions\n",
    "1. Uniform Distribution\n",
    "2. Normal Distribution\n",
    "3. Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = red>Classifier Metrics</font>\n",
    "Metrics used to evaluate the performance of machine learning classifiers — models that put each training example into one of several discrete categories.\n",
    "\n",
    "### 1. Confusion Matrix\n",
    "- Its a matrix used to indicate a classifier’s predictions on labels. \n",
    "- It contains four cells, each corresponding to one combination of a predicted true or false and an actual true or false. \n",
    "- Many classifier metrics are based on the confusion matrix, so it’s helpful to keep an image of it stored in your mind.\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*dXXjDqSN6jx9Y0KHId7ypg.png)\n",
    "\n",
    "                                 Predicted Value - Machine Learning Model prediction\n",
    "                                 Real/Value - The true value/label in the data\n",
    "\n",
    "- <font color = olive>**True Negative (TN)**</font>\n",
    "    - The actual value was **False, and the model predicted False**.\n",
    "    - It correctly identified that the person does not like dogs.\n",
    "- <font color = salmon>**False Positive (FP)**</font> \n",
    "    - The actual value was **False, and the model predicted True**.\n",
    "    - This is also known as a Type I error (rejection of a true null hypothesis).\n",
    "    - It predicted yes, the person likes dogs, but they actually don’t.\n",
    "- <font color = red>**False Negative (FN)**</font>\n",
    "    - The actual value was **True, and the model predicted False**. \n",
    "    - This is also known as a Type II error (non-rejection of a false null hypothesis).\n",
    "    - It predicted no, the person does not like dogs, but they actually do.\n",
    "- <font color = green>**True Positive**</font>\n",
    "    - The actual value was **True, and the model predicted True**.\n",
    "    - It correctly identified that the person does like dogs.\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/1400/1*Ub0nZTXYT8MxLzrz0P7jPA.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "**Important points about Model Selection metrics**\n",
    "1. <font color = blue>Accuracy</font> - both <font color = green>True Positive</font> and <font color = olive>True Negatives</font> matters to the business\n",
    "2. <font color = blue>Recall</font> - having large number of <font color = red>False Negatives</font> has a higher negative to business\n",
    "3. <font color = blue>Precision</font> - having large number of <font color = salmon>False Positives</font> has a higher cost to business\n",
    "4. <font color = blue>F1-Score</font> - want to balance <font color = red>False Negatives</font> and <font color = salmon>False Positives</font>.\n",
    "\n",
    "\n",
    "![](https://miro.medium.com/max/552/1*5CATnJ2FyNOF9xTpJ7qA5w.jpeg)\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Sensitivity/Recall \n",
    "- The number of `positives` that were accurately predicted.\n",
    "- Recall actually calculates <span style='background :pink'>how many of the **Actual Positives** our model capture through labeling it as Positive (True Positive).</span>\n",
    "- This is calculated as **TP/(TP+FN)** (note that false negatives are positives). \n",
    "- Sensitivity is a good metric to use in contexts where <span style='background :pink'>correctly predicting **positives** is important or when there is a high cost associated with **False Negative**</span>, like medical diagnoses. \n",
    "- In some cases, false positives can be dangerous (*e.g. a diagnosis of ‘no cancer’ in someone who does have cancer*) ... but it is generally agreed upon that false negatives are more deadly. \n",
    "- By having model maximize sensitivity, its ability to prioritize correctly classify positives is targeted.\n",
    "- <span style='background :turquoise'>Recall should ideally be 1 (high) for a good classifier (happens when True Postives = True Postives + False Negatives, meaning False Negatives is zero.</span>\n",
    " \n",
    "---\n",
    "\n",
    "### 3. Specificity \n",
    "- It is the number of `negatives` that were accurately predicted\n",
    "- There should be high specificity\n",
    "- This is calculated as **TN/(TN+FP)** (note that false positives are actually negatives). \n",
    "- Like sensitivity, specificity is a helpful metric in the scenario that <span style='background :pink'>accurately classifying negatives is more important than classifying positives.</span>\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Precision \n",
    "- It shows correctness achieved in positive prediction.\n",
    "- It can be thought of as the `opposite of sensitivity or recall`\n",
    "    - Sensitivity measures the proportion of actually true observations that were predicted as true\n",
    "    - Precision measures <span style='background :pink'>the proportion of predicted true observations that actually were true.</span>\n",
    "    - Precision talks about how <span style='background :pink'>precise/accurate your model is out of those predicted positive, how many of them are actual positive.</span>\n",
    "- This is measured as **TP/(TP+FP)**.\n",
    "- Precision is a good measure to determine, when the `costs of False Positive is high`. \n",
    "- For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam).\n",
    "- Precision and recall together provide a rounded view of a model’s performance.\n",
    "- <span style='background :turquoise'>Precision should ideally be 1 (high) for a good classifier (meaning False Positives is zero).</span>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*93lHZUzCKeGc60-bW8pVOw.png\" width=\"700\"/>\n",
    "\n",
    "---\n",
    "\n",
    "### 5. F1-Score\n",
    "- So, ideally in a good classifier, we want both Precision and Recall to be 1 which also means False Positive and False Negative are zero. Therefore we need a metric that takes into account both precision and recall ... F1-Score is that metric.\n",
    "- F1-score combines precision and recall through the **harmonic mean** (*harmonic mean penalizes more extreme values, opposed to the mean, which is naïve in that it weights all errors the same*)\n",
    "- The `F1 score` is used to <span style='background :pink'>measure a **test’s accuracy**</span>, and it balances the use of **precision** and **recall** to do it.\n",
    "- The harmonic mean is used since it penalizes more extreme values, opposed to the mean, which is naïve in that it weights all errors the same.\n",
    "\n",
    "$$\n",
    "F_{1}=\\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n",
    "\n",
    "- <span style='background :turquoise'>F1 Score becomes 1 only when both Precision and Recall are 1</span>\n",
    "\n",
    "---\n",
    "\n",
    "<span style='background :orange'>**IMBALANCED DATASET -- Why to use F1-score and not Accuracy**</span>\n",
    "- F1 Score is needed when you want to seek a balance between Precision and Recall.\n",
    "- Accuracy can be largely contributed by a large number of `True Negatives` which in most business circumstances, we do not focus on much; whereas `False Negative` and `False Positive` usually has business costs (tangible & intangible)\n",
    "- Thus F1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND `there is an uneven class distribution (large number of Actual Negatives)`.\n",
    "\n",
    "<span style='background :pink'>The F1 score should be used when not making mistakes is more important (False Positives and False Negatives being penalized more heavily)</span>\n",
    "<br>\n",
    "<span style='background :yellow'>Accuracy should be used when the model’s goal is to optimize performance.</span>\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "- <font color = red>**Precision**</font> is how certain you are of your true positives.\n",
    "    - Choose Precision if you want to be more **confident of your true positives**.\n",
    "        - For example, in case of spam emails, you would rather have some spam emails in your inbox rather than some regular emails in your spam box. \n",
    "        - You would like to be extra sure that email X is spam before we put it in the spam box.\n",
    "- <font color = red>**Recall**</font> is how certain you are that you are not missing any positives.\n",
    "    - Choose Recall if the occurrence of **false negatives is unaccepted/intolerable**. \n",
    "- <font color = red>**Specificity**</font> is out of **all the positive classes, how much we have predicted correctly**.\n",
    "    - Recall should be high.\n",
    "    - Choose specificity if you want to **cover all true negatives**, i.e. meaning we do not want any false alarms or false positives. \n",
    "        - For example, in case of a drug test in which all people who test positive will immediately go to jail, you would not want anyone drug-free going to jail.\n",
    "        \n",
    "<img src=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\" width=\"600\"/>\n",
    "\n",
    "---\n",
    "\n",
    "### Implementing the Metrics\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*aABip6ltJG6meLlu07EHPw.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = red>Regressor Metrics</font>\n",
    "Regression metrics are used to measure performance of a model that puts a training example on a continuous scale, such as determining the price of a house.\n",
    "\n",
    "### 1. Mean Absolute Error (MAE) \n",
    "- The most common and interpretable regression metric.\n",
    ">- The error between two numbers is simply the difference between them. \n",
    ">- The absolute error is the absolute difference. \n",
    ">- To find the mean absolute error, you must find the absolute error between corresponding values in the sets, and then find the mean of those errors.\n",
    "- It measures the average magnitude of the errors in a set of predictions, without considering their direction.\n",
    "- MAE calculates the `difference between each data point’s predicted y-value and the real y-value, then averages every difference` (the difference being calculated as the absolute value of one value minus the other).\n",
    "\n",
    "$$\n",
    "Mean Absolute Error = (\\frac{1}{n})\\sum_{i=1}^{n}\\left | y_{i} - x_{i} \\right |\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Median Absolute Error\n",
    "- Metric of evaluating the average error. \n",
    "- A measure of errors between paired observations expressing the same phenomenon.\n",
    "- While it has the benefit of moving the error distribution lower by focusing on the middle error value, it also tends to ignore extremely high or low errors that are factored into the mean absolute error.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Mean Square Error (MSE)\n",
    "- Regression metric that `punishes higher errors more`. \n",
    "    - For example\n",
    "        - An error (difference) of 2 would be weighted as 4\n",
    "        - An error of 5 would be weighted as 25\n",
    "        - Mean Square Error (MSE) finds the difference between the two errors as 21. MSE calculates the square of each data point’s predicted y-value and real y-value, then averages the squares.\n",
    "        - Mean Absolute Error (MAE) weights the difference at its face value — 3.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Root Mean Square Error (RMSE) \n",
    "- is used to give a level of interpretability that mean square error lacks.\n",
    "- By square-rooting the MSE, we achieve a metric similar to MAE in that it is on a similar scale, while still weighting higher errors at higher levels.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Mean Squared Logarithmic Error (MSLE) \n",
    "- Another common variation of the mean absolute error. \n",
    "- Because of the logarithmic nature of the error, MSLE only cares about the `percent differences`. \n",
    "- This means that MSLE will treat small differences between small values (for example, 4 and 3) the same as large differences on a large scale (for example, 1200 and 900).\n",
    "\n",
    "---\n",
    "\n",
    "### 6. R² \n",
    "- A commonly used metric (where r is known as the correlation coefficient) which measures `how much a regression model represents the proportion of the variance for a dependent variable` which can be explained by the independent variables. \n",
    "- In short, it is a good metric of `how well the data fits the regression model`.\n",
    "\n",
    "---\n",
    "\n",
    "### Implementing the Metrics\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*aABip6ltJG6meLlu07EHPw.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = red>Statistical Indicators</font>\n",
    "\n",
    "### 1. Correlation\n",
    "- A statistical measure of `how well two variables fluctuate together`. \n",
    "- Positive correlations mean that two variables fluctuate together (a positive change in one is a positive change to another)\n",
    "- A negative correlations mean that two variable change opposite one another (a positive change in one is a negative change in another). \n",
    "- Correlation is more useful for `determining the strength of the relationship between two variables`.\n",
    "- The correlation coefficient, from +1 to -1, is also known as R.\n",
    "- Formula for Correlation Coefficient (r) is \n",
    "\n",
    "$$\n",
    "r = \\frac{{}\\sum (x_i - \\overline{x})(y_i - \\overline{y})}\n",
    "{\\sqrt{\\sum (x_i - \\overline{x})^2(y_i - \\overline{y})^2}}\n",
    "$$\n",
    "\n",
    "<br> \n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*Q44XbGSYlc0pz9ZrE9SL-Q.png\" width=\"800\"/>\n",
    "\n",
    "- The correlation coefficient can be accessed using the `.corr()` function through Pandas DataFrames.\n",
    "- Calling `table.corr()` yields a correlation table (*The correlation table is symmetric and equal to 1 when a sequence is compared against itself*)\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*DvyePGWrErXFXHXl9303Kg.png\" width=\"600\"/>\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Covariance \n",
    "- A measure of the property of a function of retaining its form when the `variables are linearly transformed`.\n",
    "- Unlike correlation, however, covariance can `take on any number while correlation is limited between a range`.\n",
    "- Covariance has units (unlike correlation) and is `affected by changes in the center or scale`\n",
    "- It is less widely used as a stand-alone statistic.\n",
    "- Covariance is used in many statistics formulas, and is a useful figure to know.\n",
    "- Covariance can be used in  Python with **numpy.cov(a,b)[0][1]**, where a and b are the sequences to be compared.\n",
    "- Formula for Covariance (Cov) is \n",
    "\n",
    "$$\n",
    "Cov_{xy} = \\frac{{}\\sum (x_i - \\overline{x})(y_i - \\overline{y})}{(n-1)} = \\frac{{}\\sum (xy) - (n \\overline{xy})}{(n-1)} = \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Variance \n",
    "- Its measure of `expectation of the squared deviation of a random variable from its mean`. \n",
    "- It informally measures `how far a set of numbers are spread out from their mean`. \n",
    "- Variance can be measured in the statistics library (**import statistics**) with **statistics.variance(list)**.\n",
    "- Formula for Variance ($\\sigma^{2}$) is \n",
    "\n",
    "$$\n",
    "\\sigma^{2} = \\frac{{}\\sum (x - \\mu)^{2}}{N}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Standard Deviation \n",
    "- Its the `square root of the variance`\n",
    "- A more `scaled statistic` for how spread out a distribution is. \n",
    "- Standard deviation can be measured in the statistics library with **statistics.stdev(list)**.\n",
    "- Formula for Variance (𝜎) is \n",
    "\n",
    "$$\n",
    "\\sigma = \\sqrt{\\frac{{}\\sum (x - \\overline{x})^2}{(n - 1)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = red>Types of Distribution</font>\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*epy6pFCxBuBIglmWaLTlgg.png\" width=\"600\"/>\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Uniform Distribution \n",
    "- It is completely flat, or truly random. \n",
    "- This distribution describes an experiment where there is an arbitrary outcome that lies between `certain bounds`.\n",
    "- The bounds are defined by the parameters, a and b, which are the minimum and maximum values. \n",
    "- The interval can be either be closed (eg. [a, b]) or open (eg. (a, b)).\n",
    "- Therefore, the distribution is often abbreviated U (a, b), where U stands for uniform distribution.\n",
    "    - For example, which number of dots a dice landed on (from 1 to 6) recorded for each of 6000 throws would yields a flat distribution, with approximately 1000 throws per number of dots. \n",
    "\n",
    "---\n",
    "\n",
    "### 2. Normal Distribution (Gaussian curve)\n",
    "- Its a very common distribution that resembles a curve (one name for the distribution is the ‘Bell Curve’).\n",
    "- A normal variable has a mean “μ”, and a standard deviation “σ”. Regardless of the mean, variance and standard deviation, all normal distributions have a distinguishable bell shape.\n",
    "- Besides its common use in data science, it is where most things in the universe can be described by, like IQ or salary. It is characterized by the following features:\n",
    "    - 68% of the data is within one standard deviation of the mean.\n",
    "    - 95% of the data is within two standard deviations of the mean.\n",
    "    - 99.7% of the data is within three standard deviations of the mean.\n",
    "- Many machine learning algorithms require a normal distribution among the data. \n",
    "    - For example, logistic regression requires the residuals be normally distributed. This can be visualized and recognized with a **residplot()**.\n",
    "    \n",
    "<img src=\"https://cdn.analystprep.com/cfa-level-1-exam/wp-content/uploads/2019/10/05093814/page-123.jpg\" width=\"600\">\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Poisson Distribution \n",
    "- Can be thought of as a generalization of the normal distribution\n",
    "- A discrete probability distribution that `expresses the probability of a given number of events` occurring in a fixed interval of time or space (*if these events occur with a known constant mean rate and independently of the time since the last event*). \n",
    "- Poisson distributions, valid only for `integers` on the horizontal axis. λ (also written as μ) is the expected number of event occurrences.\n",
    "- With changing values of λ, the Poisson distribution shifts the mean left or right, with the capability of creating left-skewed or right-skewed data.\n",
    "\n",
    "<img src=\"https://www.statisticshowto.com/wp-content/uploads/2013/10/poisson-distribution.png\" width=\"400\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
